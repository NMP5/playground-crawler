{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직무별 공고 링크 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_csvfile(title, link):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    driver.get(link)\n",
    "    time.sleep(1)\n",
    "\n",
    "    list_container = driver.find_element(By.CLASS_NAME, 'List_List_container__JnQMS')\n",
    "\n",
    "    while True:\n",
    "        prev_li_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "        \n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html1 = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html1.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        html = driver.find_element(By.TAG_NAME, 'html')\n",
    "        html.send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        current_li_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "\n",
    "        if current_li_count == prev_li_count:\n",
    "            time.sleep(10)\n",
    "            reset_count = len(list_container.find_elements(By.TAG_NAME, 'li'))\n",
    "            print(\"break \" + str(reset_count))\n",
    "            if reset_count == prev_li_count:\n",
    "                break\n",
    "\n",
    "    list_items = list_container.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "    print(\"total amount is \" + str(len(list_items)))\n",
    "    \n",
    "    data = []\n",
    "    if os.path.isfile('job_link.csv'):\n",
    "        with open('job_link.csv', 'r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            data = list(reader)\n",
    "        \n",
    "    # csv_name = title + \".csv\"\n",
    "    with open('job_link.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in list_items:\n",
    "            card = item.find_element(By.CLASS_NAME, 'Card_className__u5rsb')\n",
    "            anchor = card.find_element(By.TAG_NAME, 'a')\n",
    "            link = anchor.get_attribute('href')\n",
    "            data[1:] += [(title, link)]\n",
    "            # writer.writerow([title, link])\n",
    "        writer.writerows(data)\n",
    "    \n",
    "\n",
    "    # driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"job_category.csv\", 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        job_title = row[0]\n",
    "        job_link = row[1]\n",
    "        print(job_title)\n",
    "        category_csvfile(job_title, job_link)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹사이트 직무별 공고 리스트 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무별 numbering 딕셔너리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_dict = dict()\n",
    "count = 0\n",
    "with open(\"job_category.csv\",'r',newline='') as jobcategoryfile:\n",
    "    reader = csv.reader(jobcategoryfile)\n",
    "    for job in reader:\n",
    "        job_dict[job[0]] = count\n",
    "        count += 1\n",
    "\n",
    "print(job_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무 별 link 중복 확인 후, 링크별로 정리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 링크에 중복되는 직무 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobs(link):\n",
    "    with open(\"job_link.csv\",'r', newline='') as joblistfile:\n",
    "        jobs = []\n",
    "        reader = csv.reader(joblistfile)\n",
    "        for i in reader:\n",
    "            if link == i[1]:\n",
    "                jobs.append(i[0])\n",
    "        return jobs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크를 중복없이 set로 묶고 링크 직무찾는 함수 호출 후, 링크 + 해당 직무 줄 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findJobsForLink(file):\n",
    "    total = 0\n",
    "    with open(file,'r', newline='') as joblistfile:\n",
    "        reader = csv.reader(joblistfile)\n",
    "        data = list(reader)\n",
    "        link_list = [lst[1] for lst in data]\n",
    "\n",
    "        link_set = set(link_list)\n",
    "        print(len(link_set))\n",
    "        with open(\"link_job.csv\",\"w\",newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            for link in link_set:\n",
    "                jobs = getJobs(link)\n",
    "                total += len(jobs)\n",
    "                writer.writerow([link, jobs])\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "print(findJobsForLink(\"job_link.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무 별 link 중복 확인 후, 링크별로 정리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 링크 row 당 직무 column 만들기 위해 dictionary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'웹 개발자': 0, '서버 개발자': 0, '소프트웨어 엔지니어': 0, '프론트엔드 개발자': 0, '자바 개발자': 0, 'C, C++ 개발자': 0, '안드로이드 개발자': 0, '파이썬 개발자': 0, 'Node.js 개발자': 0, 'iOS 개발자': 0, '머신러닝 엔지니어': 0, '데이터 엔지니어': 0, '시스템, 네트워크 관리자': 0, 'DevOps/ 시스템 관리자': 0, '개발 매니저': 0, '기술지원': 0, 'QA,테스트 엔지니어': 0, '데이터 사이언티스트': 0, '임베디드 개발자': 0, '보안 엔지니어': 0, '프로덕트 매니저': 0, '빅데이터 엔지니어': 0, '하드웨어 엔지니어': 0, 'PHP 개발자': 0, '블록체인 플랫폼 엔지니어': 0, '크로스플랫폼 앱 개발자': 0, 'DBA': 0, 'ERP전문가': 0, '.NET 개발자': 0, '웹 퍼블리셔': 0, '영상,음성 엔지니어': 0, '그래픽스 엔지니어': 0, '루비온레일즈 개발자': 0, 'BI 엔지니어': 0, 'VR 엔지니어': 0}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "job_dict = dict()\n",
    "with open(\"../data/job_category.csv\",'r',newline='') as jobcategoryfile:\n",
    "    reader = csv.reader(jobcategoryfile)\n",
    "    for job in reader:\n",
    "        job_dict[job[0]] = 0\n",
    "print(job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(job_dict.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 링크에 중복되는 직무 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobs(link):\n",
    "    with open(\"job_link.csv\",'r', newline='') as joblistfile:\n",
    "        jobs = []\n",
    "        reader = csv.reader(joblistfile)\n",
    "        for i in reader:\n",
    "            if link == i[1]:\n",
    "                jobs.append(i[0])\n",
    "        return jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크를 중복없이 set로 묶고 링크 직무찾는 함수 호출 후, 링크 + 해당 직무 줄 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5462\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'job_link.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m total\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[39mprint\u001b[39m(findJobsForLink(\u001b[39m\"\u001b[39;49m\u001b[39m../data/job_link.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m, in \u001b[0;36mfindJobsForLink\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m link_set:\n\u001b[0;32m     19\u001b[0m     job_cols \u001b[39m=\u001b[39m job_dict\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 20\u001b[0m     jobs \u001b[39m=\u001b[39m getJobs(link)\n\u001b[0;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m job \u001b[39min\u001b[39;00m jobs:\n\u001b[0;32m     22\u001b[0m         job_cols[job] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36mgetJobs\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetJobs\u001b[39m(link):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mjob_link.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m joblistfile:\n\u001b[0;32m      3\u001b[0m         jobs \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m         reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(joblistfile)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'job_link.csv'"
     ]
    }
   ],
   "source": [
    "def findJobsForLink(file):\n",
    "    total = 0\n",
    "    with open(file,'r', newline='') as joblistfile:\n",
    "        reader = csv.reader(joblistfile)\n",
    "        data = list(reader)\n",
    "\n",
    "        # 링크를 중복없이 set로 묶기\n",
    "        link_list = [lst[1] for lst in data]\n",
    "        link_set = set(link_list)\n",
    "\n",
    "        # 링크 unique value 개수 확인\n",
    "        print(len(link_set))\n",
    "\n",
    "        # 해당 링크 값 갖고 있는 직무 확인하기 \n",
    "        with open(\"link_job.csv\",\"w\",newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"\"] +list(job_dict.keys()))\n",
    "            for link in link_set:\n",
    "                job_cols = job_dict.copy()\n",
    "                jobs = getJobs(link)\n",
    "                for job in jobs:\n",
    "                    job_cols[job] = 1\n",
    "                total += len(jobs)\n",
    "                writer.writerow([link] + list(job_cols.values()))\n",
    "    return total\n",
    "\n",
    "import csv\n",
    "print(findJobsForLink(\"../data/job_link.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
